{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maximillian-Cat/Skin-Disease-Classification/blob/main/VGG%20Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkvMrX29rESx"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "PRM6HH053uM4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79fd63d4-9ead-41b8-91f2-c7d23c85a68c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9isbWZgcrW6n",
        "outputId": "6cd194d3-8b70-4d39-e2c7-4504fa8bf116"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/HAM/HAM_dataset\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/HAM/HAM_dataset\n",
        "ham_df = pd.read_csv(\"HAM10000_metadata.csv\") #read in the metadata\n",
        "labels = ham_df.sort_values(\"dx\") #sort the dataset by dx\n",
        "class_names = list(labels.dx.unique()) #create a list of all unique dx in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3i9iOmcMgAk",
        "outputId": "803ca2f3-c46a-4b01-c732-3f8879da2029"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/HAM\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/HAM #make a new HAM directory\n",
        "%cd /content/HAM\n",
        "for i in class_names:\n",
        "    os.makedirs(os.path.join(i)) #create subfolders of all dx in the new HAM directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "umXCIgOO11mf"
      },
      "outputs": [],
      "source": [
        "for i in class_names: #loop through all dx\n",
        "  for c in list(ham_df[ham_df[\"dx\"] == i][\"image_id\"]): #loop through all Image ID in the metadata in accordance to its dx\n",
        "    try:\n",
        "      get_image_1 = os.path.join('/content/drive/MyDrive/HAM/HAM_dataset/HAM10000_images_part_1', c+'.jpg')\n",
        "      move_image_1 = shutil.copy(get_image_1, '/content/HAM/'+i)\n",
        "    except:\n",
        "      get_image_2 = os.path.join('/content/drive/MyDrive/HAM/HAM_dataset/HAM10000_images_part_2', c+'.jpg')\n",
        "      move_image_2 = shutil.copy(get_image_2, '/content/HAM/'+i) #same as above\n",
        "\n",
        "#P/s: This code is quite inefficient and can take up to 1.5 hours to run, better solutions had yet to be found.\n",
        "#This is understandable though considering it took ~2 hours to upload all pictures onto drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hko-GQUshyH3",
        "outputId": "1ed623a0-aade-49df-b4da-ec1b7f8ba0db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Copying files: 0 files [00:00, ? files/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install split-folders\n",
        "import splitfolders\n",
        "input = \"/content/HAM\" #the starting position of the files\n",
        "output = \"/content/HAM\" #the destination of the files\n",
        "\n",
        "splitfolders.ratio(input, output = output, seed = 1337, ratio = (.8, .1, .1))\n",
        "#splitting into train/val/test subfolders, more can be read here: https://pypi.org/project/split-folders/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVbzBxRIRcOf",
        "outputId": "03911a02-3307-4ce9-f38f-c2e45aecd83f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/content/drive/MyDrive/HAM_VGG/train’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/HAM_VGG/test’: File exists\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/HAM_VGG/val’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir /content/drive/MyDrive/HAM_VGG/train\n",
        "!mkdir /content/drive/MyDrive/HAM_VGG/test\n",
        "!mkdir /content/drive/MyDrive/HAM_VGG/val\n",
        "\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/HAM_VGG/train.tar.gz\", \"/content/drive/MyDrive/HAM_VGG/train\")\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/HAM_VGG/test.tar.gz\", \"/content/drive/MyDrive/HAM_VGG/test\")\n",
        "shutil.unpack_archive(\"/content/drive/MyDrive/HAM_VGG/val.tar.gz\", \"/content/drive/MyDrive/HAM_VGG/val\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFITPgCORiGP"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import keras.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlCr8TECRm-d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3159f98f-6b61-49eb-9740-28f00638fe2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels.h5\n",
            "574710816/574710816 [==============================] - 3s 0us/step\n",
            "Found 8010 images belonging to 7 classes.\n",
            "Found 998 images belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "<ipython-input-4-02a7d3f4d265>:21: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hist_19 = model_19.fit_generator(steps_per_epoch = 100, generator = traindata, validation_data = valdata,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0925 - accuracy: 0.6526\n",
            "Epoch 1: val_accuracy improved from -inf to 0.65625, saving model to vgg19_1.h5\n",
            "100/100 [==============================] - 84s 677ms/step - loss: 1.0925 - accuracy: 0.6526 - val_loss: 1.0059 - val_accuracy: 0.6562\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8633 - accuracy: 0.6986\n",
            "Epoch 2: val_accuracy improved from 0.65625 to 0.70000, saving model to vgg19_1.h5\n",
            "100/100 [==============================] - 64s 642ms/step - loss: 0.8633 - accuracy: 0.6986 - val_loss: 0.8803 - val_accuracy: 0.7000\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8001 - accuracy: 0.7250\n",
            "Epoch 3: val_accuracy did not improve from 0.70000\n",
            "100/100 [==============================] - 80s 797ms/step - loss: 0.8001 - accuracy: 0.7250 - val_loss: 1.0101 - val_accuracy: 0.6375\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7735 - accuracy: 0.7322\n",
            "Epoch 4: val_accuracy improved from 0.70000 to 0.70312, saving model to vgg19_1.h5\n",
            "100/100 [==============================] - 80s 797ms/step - loss: 0.7735 - accuracy: 0.7322 - val_loss: 0.8782 - val_accuracy: 0.7031\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7112 - accuracy: 0.7459\n",
            "Epoch 5: val_accuracy improved from 0.70312 to 0.70625, saving model to vgg19_1.h5\n",
            "100/100 [==============================] - 73s 726ms/step - loss: 0.7112 - accuracy: 0.7459 - val_loss: 0.7873 - val_accuracy: 0.7063\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6838 - accuracy: 0.7591\n",
            "Epoch 6: val_accuracy improved from 0.70625 to 0.73438, saving model to vgg19_1.h5\n",
            "100/100 [==============================] - 64s 641ms/step - loss: 0.6838 - accuracy: 0.7591 - val_loss: 0.8473 - val_accuracy: 0.7344\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.7728\n",
            "Epoch 7: val_accuracy improved from 0.73438 to 0.74063, saving model to vgg19_1.h5\n",
            "100/100 [==============================] - 68s 676ms/step - loss: 0.6452 - accuracy: 0.7728 - val_loss: 0.9115 - val_accuracy: 0.7406\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6302 - accuracy: 0.7803\n",
            "Epoch 8: val_accuracy did not improve from 0.74063\n",
            "100/100 [==============================] - 60s 596ms/step - loss: 0.6302 - accuracy: 0.7803 - val_loss: 0.9434 - val_accuracy: 0.7063\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5856 - accuracy: 0.7894\n",
            "Epoch 9: val_accuracy improved from 0.74063 to 0.74375, saving model to vgg19_1.h5\n",
            "100/100 [==============================] - 63s 626ms/step - loss: 0.5856 - accuracy: 0.7894 - val_loss: 0.7518 - val_accuracy: 0.7437\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6047 - accuracy: 0.7822\n",
            "Epoch 10: val_accuracy did not improve from 0.74375\n",
            "100/100 [==============================] - 57s 572ms/step - loss: 0.6047 - accuracy: 0.7822 - val_loss: 0.8753 - val_accuracy: 0.7156\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5712 - accuracy: 0.7828\n",
            "Epoch 11: val_accuracy did not improve from 0.74375\n",
            "100/100 [==============================] - 55s 550ms/step - loss: 0.5712 - accuracy: 0.7828 - val_loss: 0.8894 - val_accuracy: 0.7125\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.7931\n",
            "Epoch 12: val_accuracy did not improve from 0.74375\n",
            "100/100 [==============================] - 55s 545ms/step - loss: 0.5671 - accuracy: 0.7931 - val_loss: 0.6833 - val_accuracy: 0.7312\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5457 - accuracy: 0.8068\n",
            "Epoch 13: val_accuracy did not improve from 0.74375\n",
            "100/100 [==============================] - 59s 588ms/step - loss: 0.5457 - accuracy: 0.8068 - val_loss: 0.8242 - val_accuracy: 0.7063\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4802 - accuracy: 0.8247\n",
            "Epoch 14: val_accuracy did not improve from 0.74375\n",
            "100/100 [==============================] - 59s 591ms/step - loss: 0.4802 - accuracy: 0.8247 - val_loss: 0.9142 - val_accuracy: 0.7188\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4895 - accuracy: 0.8200\n",
            "Epoch 15: val_accuracy did not improve from 0.74375\n",
            "100/100 [==============================] - 55s 544ms/step - loss: 0.4895 - accuracy: 0.8200 - val_loss: 0.9342 - val_accuracy: 0.6812\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4844 - accuracy: 0.8266\n",
            "Epoch 16: val_accuracy improved from 0.74375 to 0.76250, saving model to vgg19_1.h5\n",
            "100/100 [==============================] - 57s 565ms/step - loss: 0.4844 - accuracy: 0.8266 - val_loss: 0.8499 - val_accuracy: 0.7625\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4902 - accuracy: 0.8225\n",
            "Epoch 17: val_accuracy improved from 0.76250 to 0.76875, saving model to vgg19_1.h5\n",
            "100/100 [==============================] - 58s 582ms/step - loss: 0.4902 - accuracy: 0.8225 - val_loss: 0.7464 - val_accuracy: 0.7688\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4785 - accuracy: 0.8269\n",
            "Epoch 18: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 60s 604ms/step - loss: 0.4785 - accuracy: 0.8269 - val_loss: 0.8506 - val_accuracy: 0.7063\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4757 - accuracy: 0.8169\n",
            "Epoch 19: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 55s 546ms/step - loss: 0.4757 - accuracy: 0.8169 - val_loss: 0.8338 - val_accuracy: 0.7375\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4481 - accuracy: 0.8297\n",
            "Epoch 20: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 54s 536ms/step - loss: 0.4481 - accuracy: 0.8297 - val_loss: 0.7489 - val_accuracy: 0.7656\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.8425\n",
            "Epoch 21: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 53s 531ms/step - loss: 0.4413 - accuracy: 0.8425 - val_loss: 0.8440 - val_accuracy: 0.7437\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4395 - accuracy: 0.8388\n",
            "Epoch 22: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 53s 531ms/step - loss: 0.4395 - accuracy: 0.8388 - val_loss: 0.9662 - val_accuracy: 0.7000\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3989 - accuracy: 0.8603\n",
            "Epoch 23: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 58s 577ms/step - loss: 0.3989 - accuracy: 0.8603 - val_loss: 0.9255 - val_accuracy: 0.7031\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4167 - accuracy: 0.8500\n",
            "Epoch 24: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 58s 579ms/step - loss: 0.4167 - accuracy: 0.8500 - val_loss: 0.9119 - val_accuracy: 0.7188\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3944 - accuracy: 0.8544\n",
            "Epoch 25: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 53s 532ms/step - loss: 0.3944 - accuracy: 0.8544 - val_loss: 0.8813 - val_accuracy: 0.7125\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3734 - accuracy: 0.8653\n",
            "Epoch 26: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 53s 527ms/step - loss: 0.3734 - accuracy: 0.8653 - val_loss: 0.8439 - val_accuracy: 0.7219\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3801 - accuracy: 0.8650\n",
            "Epoch 27: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 58s 577ms/step - loss: 0.3801 - accuracy: 0.8650 - val_loss: 0.7856 - val_accuracy: 0.7656\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3715 - accuracy: 0.8625\n",
            "Epoch 28: val_accuracy did not improve from 0.76875\n",
            "100/100 [==============================] - 53s 528ms/step - loss: 0.3715 - accuracy: 0.8625 - val_loss: 0.9093 - val_accuracy: 0.7344\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.8775\n",
            "Epoch 29: val_accuracy improved from 0.76875 to 0.78438, saving model to vgg19_1.h5\n",
            "100/100 [==============================] - 56s 559ms/step - loss: 0.3586 - accuracy: 0.8775 - val_loss: 0.7185 - val_accuracy: 0.7844\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3731 - accuracy: 0.8590\n",
            "Epoch 30: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 530ms/step - loss: 0.3731 - accuracy: 0.8590 - val_loss: 0.9141 - val_accuracy: 0.7156\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3689 - accuracy: 0.8700\n",
            "Epoch 31: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 54s 535ms/step - loss: 0.3689 - accuracy: 0.8700 - val_loss: 0.9161 - val_accuracy: 0.7312\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3196 - accuracy: 0.8841\n",
            "Epoch 32: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 525ms/step - loss: 0.3196 - accuracy: 0.8841 - val_loss: 0.8453 - val_accuracy: 0.7594\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.8722\n",
            "Epoch 33: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.3572 - accuracy: 0.8722 - val_loss: 1.0291 - val_accuracy: 0.7250\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8794\n",
            "Epoch 34: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 525ms/step - loss: 0.3302 - accuracy: 0.8794 - val_loss: 0.9503 - val_accuracy: 0.7281\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3349 - accuracy: 0.8788\n",
            "Epoch 35: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 525ms/step - loss: 0.3349 - accuracy: 0.8788 - val_loss: 1.0737 - val_accuracy: 0.7219\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.8773\n",
            "Epoch 36: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 52s 524ms/step - loss: 0.3388 - accuracy: 0.8773 - val_loss: 0.9370 - val_accuracy: 0.7063\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3123 - accuracy: 0.8889\n",
            "Epoch 37: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 57s 574ms/step - loss: 0.3123 - accuracy: 0.8889 - val_loss: 0.7321 - val_accuracy: 0.7812\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3030 - accuracy: 0.8914\n",
            "Epoch 38: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.3030 - accuracy: 0.8914 - val_loss: 0.8300 - val_accuracy: 0.7531\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3473 - accuracy: 0.8672\n",
            "Epoch 39: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 533ms/step - loss: 0.3473 - accuracy: 0.8672 - val_loss: 0.9911 - val_accuracy: 0.7063\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3397 - accuracy: 0.8757\n",
            "Epoch 40: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 52s 515ms/step - loss: 0.3397 - accuracy: 0.8757 - val_loss: 0.9186 - val_accuracy: 0.7500\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3021 - accuracy: 0.8896\n",
            "Epoch 41: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 527ms/step - loss: 0.3021 - accuracy: 0.8896 - val_loss: 0.8268 - val_accuracy: 0.7125\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2917 - accuracy: 0.8980\n",
            "Epoch 42: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 52s 521ms/step - loss: 0.2917 - accuracy: 0.8980 - val_loss: 0.9456 - val_accuracy: 0.7156\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3216 - accuracy: 0.8769\n",
            "Epoch 43: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.3216 - accuracy: 0.8769 - val_loss: 1.0839 - val_accuracy: 0.7563\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2895 - accuracy: 0.8933\n",
            "Epoch 44: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 57s 572ms/step - loss: 0.2895 - accuracy: 0.8933 - val_loss: 0.9415 - val_accuracy: 0.7094\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2945 - accuracy: 0.8969\n",
            "Epoch 45: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.2945 - accuracy: 0.8969 - val_loss: 0.8305 - val_accuracy: 0.7063\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2912 - accuracy: 0.8877\n",
            "Epoch 46: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 58s 579ms/step - loss: 0.2912 - accuracy: 0.8877 - val_loss: 0.9410 - val_accuracy: 0.7156\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2620 - accuracy: 0.9094\n",
            "Epoch 47: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.2620 - accuracy: 0.9094 - val_loss: 1.1147 - val_accuracy: 0.6875\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2751 - accuracy: 0.9031\n",
            "Epoch 48: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 524ms/step - loss: 0.2751 - accuracy: 0.9031 - val_loss: 1.0378 - val_accuracy: 0.6938\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2739 - accuracy: 0.8997\n",
            "Epoch 49: val_accuracy did not improve from 0.78438\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.2739 - accuracy: 0.8997 - val_loss: 0.9861 - val_accuracy: 0.7250\n",
            "Epoch 49: early stopping\n"
          ]
        }
      ],
      "source": [
        "basemodel_19 = VGG19()\n",
        "model_19 = tf.keras.Sequential(basemodel_19.layers[:-1])\n",
        "model_19.add(tf.keras.layers.Dense(7, activation = 'softmax'))\n",
        "for layer in basemodel_19.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "traindata = ImageDataGenerator().flow_from_directory(directory = \"/content/drive/MyDrive/HAM_VGG/train\",\n",
        "                                                     target_size = (224,224), class_mode = \"categorical\")\n",
        "valdata = ImageDataGenerator().flow_from_directory(directory = \"/content/drive/MyDrive/HAM_VGG/val\",\n",
        "                                                    target_size=(224,224), class_mode = \"categorical\")\n",
        "\n",
        "optimizer = Adam(learning_rate = 0.001)\n",
        "model_19.compile(optimizer = optimizer, loss = keras.losses.categorical_crossentropy, metrics = ['accuracy'])\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"vgg19_1.h5\", monitor = 'val_accuracy', verbose = 1, save_best_only = True,\n",
        "                             save_weights_only = False, mode = 'auto', period = 1)\n",
        "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 20, verbose = 1, mode = 'auto')\n",
        "\n",
        "hist_19 = model_19.fit_generator(steps_per_epoch = 100, generator = traindata, validation_data = valdata,\n",
        "                                 validation_steps = 10, epochs = 50, callbacks = [checkpoint, earlystop])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/vgg19_1.h5 /content/drive/MyDrive/HAM_VGG\n",
        "#model_19 = load_model(\"/content/drive/MyDrive/HAM_VGG/vgg19_1.h5\")\n",
        "testdata = ImageDataGenerator().flow_from_directory(directory = \"/content/drive/MyDrive/HAM_VGG/test\",\n",
        "                                                    target_size=(224,224), class_mode = \"categorical\")\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "prediction = model_19.predict_generator(testdata)\n",
        "prediction = np.argmax(prediction, axis = 1)\n",
        "\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(testdata.classes, prediction))\n",
        "\n",
        "print('Classification Report')\n",
        "target_names = ['Akiec', 'Bcc', 'Bkl','Df', 'Mel', 'Nv', 'Vasc',]\n",
        "print(classification_report(testdata.classes, prediction, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGi4GxdgUrh5",
        "outputId": "e6f9d229-8091-439a-9615-046bbb614c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1007 images belonging to 7 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-05d34a861fcf>:7: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  prediction = model_19.predict_generator(testdata)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[  3   1   1   0   4  24   1]\n",
            " [  1   4   7   0   9  31   0]\n",
            " [  2   5  13   1  13  76   1]\n",
            " [  0   0   1   1   1   9   0]\n",
            " [  2   0  16   0  19  72   3]\n",
            " [ 18  20  76   5  92 454   6]\n",
            " [  0   0   1   0   2  11   1]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Akiec       0.12      0.09      0.10        34\n",
            "         Bcc       0.13      0.08      0.10        52\n",
            "         Bkl       0.11      0.12      0.12       111\n",
            "          Df       0.14      0.08      0.11        12\n",
            "         Mel       0.14      0.17      0.15       112\n",
            "          Nv       0.67      0.68      0.67       671\n",
            "        Vasc       0.08      0.07      0.07        15\n",
            "\n",
            "    accuracy                           0.49      1007\n",
            "   macro avg       0.20      0.18      0.19      1007\n",
            "weighted avg       0.49      0.49      0.49      1007\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basemodel_16 = VGG16()\n",
        "model_16 = tf.keras.Sequential(basemodel_16.layers[:-1])\n",
        "model_16.add(tf.keras.layers.Dense(7, activation = 'softmax'))\n",
        "for layer in basemodel_16.layers[:-1]:\n",
        "    layer.trainable = False\n",
        "\n",
        "optimizer = Adam(learning_rate = 0.001)\n",
        "model_16.compile(optimizer = optimizer, loss = keras.losses.categorical_crossentropy,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor = 'val_accuracy', verbose = 1, save_best_only = True,\n",
        "                             save_weights_only = False, mode = 'auto', period = 1)\n",
        "earlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience=20, verbose = 1, mode = 'auto')\n",
        "\n",
        "hist_16 = model_16.fit_generator(steps_per_epoch = 100, generator = traindata, validation_data = valdata,\n",
        "                                 validation_steps = 10, epochs = 50, callbacks = [checkpoint, earlystop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUR9LAAbjV_c",
        "outputId": "4cc95a9f-20d7-42c4-ed39-18044f95d1b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467096/553467096 [==============================] - 6s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "<ipython-input-6-39305b6b39b8>:15: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  hist_16 = model_16.fit_generator(steps_per_epoch = 100, generator = traindata, validation_data = valdata,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 1.0793 - accuracy: 0.6644\n",
            "Epoch 1: val_accuracy improved from -inf to 0.69687, saving model to vgg16_1.h5\n",
            "100/100 [==============================] - 65s 645ms/step - loss: 1.0793 - accuracy: 0.6644 - val_loss: 0.8356 - val_accuracy: 0.6969\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8245 - accuracy: 0.7122\n",
            "Epoch 2: val_accuracy did not improve from 0.69687\n",
            "100/100 [==============================] - 58s 577ms/step - loss: 0.8245 - accuracy: 0.7122 - val_loss: 0.9787 - val_accuracy: 0.6875\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.8494 - accuracy: 0.7111\n",
            "Epoch 3: val_accuracy improved from 0.69687 to 0.71250, saving model to vgg16_1.h5\n",
            "100/100 [==============================] - 57s 569ms/step - loss: 0.8494 - accuracy: 0.7111 - val_loss: 1.1160 - val_accuracy: 0.7125\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7749 - accuracy: 0.7325\n",
            "Epoch 4: val_accuracy did not improve from 0.71250\n",
            "100/100 [==============================] - 55s 547ms/step - loss: 0.7749 - accuracy: 0.7325 - val_loss: 0.9189 - val_accuracy: 0.6969\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.7466 - accuracy: 0.7462\n",
            "Epoch 5: val_accuracy did not improve from 0.71250\n",
            "100/100 [==============================] - 54s 538ms/step - loss: 0.7466 - accuracy: 0.7462 - val_loss: 0.9564 - val_accuracy: 0.6656\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6750 - accuracy: 0.7666\n",
            "Epoch 6: val_accuracy did not improve from 0.71250\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.6750 - accuracy: 0.7666 - val_loss: 0.9394 - val_accuracy: 0.6812\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.7703\n",
            "Epoch 7: val_accuracy improved from 0.71250 to 0.73125, saving model to vgg16_1.h5\n",
            "100/100 [==============================] - 57s 568ms/step - loss: 0.6335 - accuracy: 0.7703 - val_loss: 0.8073 - val_accuracy: 0.7312\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.6123 - accuracy: 0.7800\n",
            "Epoch 8: val_accuracy did not improve from 0.73125\n",
            "100/100 [==============================] - 55s 554ms/step - loss: 0.6123 - accuracy: 0.7800 - val_loss: 0.8076 - val_accuracy: 0.7188\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5832 - accuracy: 0.7909\n",
            "Epoch 9: val_accuracy did not improve from 0.73125\n",
            "100/100 [==============================] - 54s 538ms/step - loss: 0.5832 - accuracy: 0.7909 - val_loss: 0.7993 - val_accuracy: 0.7312\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5782 - accuracy: 0.7925\n",
            "Epoch 10: val_accuracy did not improve from 0.73125\n",
            "100/100 [==============================] - 58s 576ms/step - loss: 0.5782 - accuracy: 0.7925 - val_loss: 0.8211 - val_accuracy: 0.7188\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5283 - accuracy: 0.8009\n",
            "Epoch 11: val_accuracy did not improve from 0.73125\n",
            "100/100 [==============================] - 58s 578ms/step - loss: 0.5283 - accuracy: 0.8009 - val_loss: 0.8659 - val_accuracy: 0.6906\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.8034\n",
            "Epoch 12: val_accuracy improved from 0.73125 to 0.74375, saving model to vgg16_1.h5\n",
            "100/100 [==============================] - 56s 562ms/step - loss: 0.5334 - accuracy: 0.8034 - val_loss: 0.7557 - val_accuracy: 0.7437\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5286 - accuracy: 0.8100\n",
            "Epoch 13: val_accuracy did not improve from 0.74375\n",
            "100/100 [==============================] - 54s 537ms/step - loss: 0.5286 - accuracy: 0.8100 - val_loss: 0.7921 - val_accuracy: 0.7281\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.8081\n",
            "Epoch 14: val_accuracy improved from 0.74375 to 0.75625, saving model to vgg16_1.h5\n",
            "100/100 [==============================] - 57s 568ms/step - loss: 0.5400 - accuracy: 0.8081 - val_loss: 0.7645 - val_accuracy: 0.7563\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5090 - accuracy: 0.8166\n",
            "Epoch 15: val_accuracy did not improve from 0.75625\n",
            "100/100 [==============================] - 54s 537ms/step - loss: 0.5090 - accuracy: 0.8166 - val_loss: 0.9196 - val_accuracy: 0.7156\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.8172\n",
            "Epoch 16: val_accuracy did not improve from 0.75625\n",
            "100/100 [==============================] - 54s 537ms/step - loss: 0.4980 - accuracy: 0.8172 - val_loss: 0.7626 - val_accuracy: 0.7375\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5064 - accuracy: 0.8077\n",
            "Epoch 17: val_accuracy did not improve from 0.75625\n",
            "100/100 [==============================] - 54s 537ms/step - loss: 0.5064 - accuracy: 0.8077 - val_loss: 0.8887 - val_accuracy: 0.7188\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4353 - accuracy: 0.8406\n",
            "Epoch 18: val_accuracy did not improve from 0.75625\n",
            "100/100 [==============================] - 58s 582ms/step - loss: 0.4353 - accuracy: 0.8406 - val_loss: 0.9109 - val_accuracy: 0.7250\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4501 - accuracy: 0.8334\n",
            "Epoch 19: val_accuracy did not improve from 0.75625\n",
            "100/100 [==============================] - 58s 575ms/step - loss: 0.4501 - accuracy: 0.8334 - val_loss: 1.0040 - val_accuracy: 0.7312\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4495 - accuracy: 0.8364\n",
            "Epoch 20: val_accuracy did not improve from 0.75625\n",
            "100/100 [==============================] - 58s 579ms/step - loss: 0.4495 - accuracy: 0.8364 - val_loss: 0.7662 - val_accuracy: 0.7500\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4529 - accuracy: 0.8326\n",
            "Epoch 21: val_accuracy did not improve from 0.75625\n",
            "100/100 [==============================] - 54s 537ms/step - loss: 0.4529 - accuracy: 0.8326 - val_loss: 0.8956 - val_accuracy: 0.6781\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4562 - accuracy: 0.8313\n",
            "Epoch 22: val_accuracy did not improve from 0.75625\n",
            "100/100 [==============================] - 53s 531ms/step - loss: 0.4562 - accuracy: 0.8313 - val_loss: 0.8600 - val_accuracy: 0.7531\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4189 - accuracy: 0.8424\n",
            "Epoch 23: val_accuracy did not improve from 0.75625\n",
            "100/100 [==============================] - 54s 535ms/step - loss: 0.4189 - accuracy: 0.8424 - val_loss: 0.7717 - val_accuracy: 0.7563\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4007 - accuracy: 0.8541\n",
            "Epoch 24: val_accuracy improved from 0.75625 to 0.78125, saving model to vgg16_1.h5\n",
            "100/100 [==============================] - 60s 601ms/step - loss: 0.4007 - accuracy: 0.8541 - val_loss: 0.8086 - val_accuracy: 0.7812\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3945 - accuracy: 0.8515\n",
            "Epoch 25: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 53s 528ms/step - loss: 0.3945 - accuracy: 0.8515 - val_loss: 0.8417 - val_accuracy: 0.7188\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.4202 - accuracy: 0.8509\n",
            "Epoch 26: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 58s 575ms/step - loss: 0.4202 - accuracy: 0.8509 - val_loss: 0.9824 - val_accuracy: 0.7000\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3964 - accuracy: 0.8534\n",
            "Epoch 27: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 57s 566ms/step - loss: 0.3964 - accuracy: 0.8534 - val_loss: 0.9272 - val_accuracy: 0.7156\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3943 - accuracy: 0.8505\n",
            "Epoch 28: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 57s 571ms/step - loss: 0.3943 - accuracy: 0.8505 - val_loss: 0.8656 - val_accuracy: 0.7688\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3728 - accuracy: 0.8597\n",
            "Epoch 29: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 52s 525ms/step - loss: 0.3728 - accuracy: 0.8597 - val_loss: 0.8529 - val_accuracy: 0.7594\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3604 - accuracy: 0.8672\n",
            "Epoch 30: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 52s 518ms/step - loss: 0.3604 - accuracy: 0.8672 - val_loss: 0.9684 - val_accuracy: 0.7312\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3623 - accuracy: 0.8716\n",
            "Epoch 31: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 57s 568ms/step - loss: 0.3623 - accuracy: 0.8716 - val_loss: 0.8780 - val_accuracy: 0.7094\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3456 - accuracy: 0.8691\n",
            "Epoch 32: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 57s 570ms/step - loss: 0.3456 - accuracy: 0.8691 - val_loss: 0.8355 - val_accuracy: 0.7469\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3595 - accuracy: 0.8729\n",
            "Epoch 33: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 57s 568ms/step - loss: 0.3595 - accuracy: 0.8729 - val_loss: 0.7548 - val_accuracy: 0.7812\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3420 - accuracy: 0.8703\n",
            "Epoch 34: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.3420 - accuracy: 0.8703 - val_loss: 0.9213 - val_accuracy: 0.7250\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3584 - accuracy: 0.8660\n",
            "Epoch 35: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 52s 522ms/step - loss: 0.3584 - accuracy: 0.8660 - val_loss: 1.0401 - val_accuracy: 0.7312\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3603 - accuracy: 0.8684\n",
            "Epoch 36: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 57s 572ms/step - loss: 0.3603 - accuracy: 0.8684 - val_loss: 0.8252 - val_accuracy: 0.7469\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3678 - accuracy: 0.8663\n",
            "Epoch 37: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 52s 523ms/step - loss: 0.3678 - accuracy: 0.8663 - val_loss: 0.9353 - val_accuracy: 0.7063\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3188 - accuracy: 0.8853\n",
            "Epoch 38: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 53s 526ms/step - loss: 0.3188 - accuracy: 0.8853 - val_loss: 1.2500 - val_accuracy: 0.6938\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.8687\n",
            "Epoch 39: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 54s 538ms/step - loss: 0.3477 - accuracy: 0.8687 - val_loss: 0.9796 - val_accuracy: 0.6906\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2974 - accuracy: 0.8946\n",
            "Epoch 40: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 53s 529ms/step - loss: 0.2974 - accuracy: 0.8946 - val_loss: 0.9863 - val_accuracy: 0.7375\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2939 - accuracy: 0.8938\n",
            "Epoch 41: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 53s 532ms/step - loss: 0.2939 - accuracy: 0.8938 - val_loss: 0.8535 - val_accuracy: 0.7219\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.3067 - accuracy: 0.8892\n",
            "Epoch 42: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 58s 578ms/step - loss: 0.3067 - accuracy: 0.8892 - val_loss: 0.8316 - val_accuracy: 0.7688\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.8988\n",
            "Epoch 43: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 53s 533ms/step - loss: 0.2736 - accuracy: 0.8988 - val_loss: 1.0465 - val_accuracy: 0.7094\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.2820 - accuracy: 0.8975\n",
            "Epoch 44: val_accuracy did not improve from 0.78125\n",
            "100/100 [==============================] - 54s 543ms/step - loss: 0.2820 - accuracy: 0.8975 - val_loss: 0.9412 - val_accuracy: 0.7531\n",
            "Epoch 44: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/vgg16_1.h5 /content/drive/MyDrive/HAM_VGG\n",
        "#model_16 = load_model(\"/content/drive/MyDrive/HAM_VGG/vgg16_1.h5\")\n",
        "\n",
        "prediction = model_16.predict_generator(testdata)\n",
        "prediction = np.argmax(prediction, axis=1)\n",
        "\n",
        "print('Confusion Matrix')\n",
        "print(confusion_matrix(testdata.classes, prediction))\n",
        "\n",
        "print('Classification Report')\n",
        "target_names = ['Akiec', 'Bcc', 'Bkl','Df', 'Mel', 'Nv', 'Vasc',]\n",
        "print(classification_report(testdata.classes, prediction, target_names = target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YsMrdegyjop_",
        "outputId": "d7c3bd93-9a6a-4da6-f7a0-35aa1f8d7fee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-74453f70e338>:4: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  prediction = model_16.predict_generator(testdata)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix\n",
            "[[  0   1   2   0   3  28   0]\n",
            " [  0   3   3   1   5  40   0]\n",
            " [  0   6   8   0   7  89   1]\n",
            " [  0   1   0   0   2   9   0]\n",
            " [  0   1   3   1   9  97   1]\n",
            " [  7  36  18   3  64 540   3]\n",
            " [  1   0   1   0   1  12   0]]\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Akiec       0.00      0.00      0.00        34\n",
            "         Bcc       0.06      0.06      0.06        52\n",
            "         Bkl       0.23      0.07      0.11       111\n",
            "          Df       0.00      0.00      0.00        12\n",
            "         Mel       0.10      0.08      0.09       112\n",
            "          Nv       0.66      0.80      0.73       671\n",
            "        Vasc       0.00      0.00      0.00        15\n",
            "\n",
            "    accuracy                           0.56      1007\n",
            "   macro avg       0.15      0.14      0.14      1007\n",
            "weighted avg       0.48      0.56      0.51      1007\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import Conv2D, Dense, Flatten, MaxPool2D\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg19 import VGG19\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import keras.metrics"
      ],
      "metadata": {
        "id": "yW1-4uHW78Dj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VGG16()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj4cEC_o8AKl",
        "outputId": "5cb65bda-f81b-45d5-ab73-e8e566646c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 1000)              4097000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pickle\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Input, Flatten, Dense, Dropout\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "raw_folder = \"/content/drive/MyDrive/HAM_VGG/train\"\n",
        "def save_data(raw_folder=raw_folder):\n",
        "\n",
        "    dest_size = (128, 128)\n",
        "    print(\"Bắt đầu xử lý ảnh...\")\n",
        "\n",
        "    pixels = []\n",
        "    labels = []\n",
        "\n",
        "    # Lặp qua các folder con trong thư mục raw\n",
        "    for folder in listdir(raw_folder):\n",
        "        if folder!='.DS_Store':\n",
        "            print(\"Folder=\",folder)\n",
        "            # Lặp qua các file trong từng thư mục chứa các em\n",
        "            for file in listdir(raw_folder  + folder):\n",
        "                if file!='.DS_Store':\n",
        "                    print(\"File=\", file)\n",
        "                    pixels.append( cv2.resize(cv2.imread(raw_folder  + folder +\"/\" + file),dsize=(128,128)))\n",
        "                    labels.append( folder)\n",
        "\n",
        "    pixels = np.array(pixels)\n",
        "    labels = np.array(labels)#.reshape(-1,1)\n",
        "\n",
        "    from sklearn.preprocessing import LabelBinarizer\n",
        "    encoder = LabelBinarizer()\n",
        "    labels = encoder.fit_transform(labels)\n",
        "    print(labels)\n",
        "\n",
        "    file = open('pix.data', 'wb')\n",
        "    # dump information to that file\n",
        "    pickle.dump((pixels,labels), file)\n",
        "    # close the file\n",
        "    file.close()\n",
        "\n",
        "    return\n",
        "\n",
        "def load_data():\n",
        "    file = open('pix.data', 'rb')\n",
        "\n",
        "    # dump information to that file\n",
        "    (pixels, labels) = pickle.load(file)\n",
        "\n",
        "    # close the file\n",
        "    file.close()\n",
        "\n",
        "    print(pixels.shape)\n",
        "    print(labels.shape)\n",
        "\n",
        "\n",
        "    return pixels, labels\n",
        "\n",
        "#save_data()\n",
        "X,y = load_data()\n",
        "#random.shuffle(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=100)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "def get_model():\n",
        "    model_vgg16_conv = VGG16(weights='imagenet', include_top=False)\n",
        "\n",
        "    # Dong bang cac layer\n",
        "    for layer in model_vgg16_conv.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Tao model\n",
        "    input = Input(shape=(128, 128, 3), name='image_input')\n",
        "    output_vgg16_conv = model_vgg16_conv(input)\n",
        "\n",
        "    # Them cac layer FC va Dropout\n",
        "    x = Flatten(name='flatten')(output_vgg16_conv)\n",
        "    x = Dense(4096, activation='relu', name='fc1')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(4096, activation='relu', name='fc2')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(7, activation='softmax', name='predictions')(x)\n",
        "\n",
        "    # Compile\n",
        "    my_model = Model(inputs=input, outputs=x)\n",
        "    my_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return my_model\n",
        "\n",
        "vggmodel = get_model()\n",
        "\n",
        "filepath=\"weights-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "# construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.1,\n",
        "    rescale=1./255,\n",
        "\twidth_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "\thorizontal_flip=True,\n",
        "    brightness_range=[0.2,1.5], fill_mode=\"nearest\")\n",
        "\n",
        "aug_val = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "vgghist=vggmodel.fit_generator(aug.flow(X_train, y_train, batch_size=64),\n",
        "                               epochs=50,# steps_per_epoch=len(X_train)//64,\n",
        "                               validation_data=aug.flow(X_test,y_test,\n",
        "                               batch_size=64),\n",
        "                               callbacks=callbacks_list)\n",
        "\n",
        "vggmodel.save(\"vggmodel.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "xPOhw4YQIqg7",
        "outputId": "fe774476-3519-4697-d7e6-6fa367552901"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-33ccd65ce20e>\u001b[0m in \u001b[0;36m<cell line: 67>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m#save_data()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;31m#random.shuffle(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-33ccd65ce20e>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pix.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# dump information to that file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pix.data'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}